# 一 、 PCA(主成分分析，peincipal Component Analysis)

## 1. 什么是PCA，用处是什么？

- 非监督学习
- 目的：原来的数据集是**d维**，转换成**k维**的数据，k<d，**新的**k维数据尽可能多的包含原来d维数据的信息（**即降维**），最小化损失，最大化包含原来n维的数据信息（**用协方差衡量两个维度之间是否有关系，两个维度之间的线性相关性有多大**）
- 用处
  - 聚类（clustering）：将复杂的多维数据点，简化成少量数据点，易于分簇
  - 降维：降低高维数据，简化计算；降低维度、去噪、压缩
- [[数学原理]]([PCA的数学原理(非常值得阅读)！！！！_脚踏实地-CSDN博客_pca的数学原理](https://blog.csdn.net/xiaojidan2011/article/details/11595869))

## 2. 如何选择投影方向？

- 二维降到一维的问题，要在二维平面中选择一个方向，将所有数据都投影到这个方向的直线上，用投影值表示原始记录
- 如何选择这个方向，才能尽可能地保留最多地原始数据呢？
  - 直观上看，**投影后地投影值尽可能地分散，这种分散程度，用数学上地方差来表述**
  - 找一个线性变化，让数据投影的方差最大化，
  - **想要的最大方差就是协方差矩阵最大的特征值，最佳投影方向就是最大特征值所对应的特征向量**

##  3. PCA求解过程

设又m条n维数据

- 将原始数据按列组成n行m列的矩阵X
- 将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值
- 求出协方差矩阵
- 求出协方差矩阵的特征值及其对应的特征向量   - ->（**想要的最大方差就是协方差矩阵最大的特征值，最佳投影方向就是最大特征值所对应的特征向量**）
- 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P
- Y = PX 即为降维到k维后的数据

# 二、 LDA(Linear Discriminant Analysis,线性判别分析)

## 1. 什么是LDA?

- LDA的中心思想是**最大化类间距离，最小化类内距离**

![image-20210729193622224](readme.assets/image-20210729193622224.png)

- 用处：
  - 分类
  - 降维：将带上标签的数据点，通过投影的方法，投影到维度更低的空间上，是的投影后的点，会形成按类别区分，一簇一簇的情况，相同类别的点，将会在投影后的空间更加接近（但是要尽可能地减少不同特征地重叠）
- [[数学原理]](https://blog.csdn.net/feilong_csdn/article/details/60964027)

## 2. LDA求解过程

LDA用于降维的流程：

- 计算每个类别的均值$\mu_i$，全局样本均值$\mu$
- 计算类内散度矩阵$S_w$，全局散度矩阵$S_t$，类间散度矩阵$S_b$
- 对矩阵$S_w^{-1}S_b$做特征值分解
- 取最大的$d^`$个特征值所对应的特征向量
- 计算投影矩阵

## 3. 如何确定LDA的topic个数？

- 基于经验主观判断、不断调试、操作性强
- 基于困惑度（主要是比较两个模型之间的好坏）
- 使用Log-边际似然函数的方法
- 非参数方法：Teh提出的基于狄利克雷过程的HDP法。
- 基于主题之间的相似度：计算主题向量之间的余弦相似度，KL距离等

## 4.  如何用主题模型解决推荐系统中的冷启动问题？ 

推荐系统中的冷启动问题是指在没有大量用户数据的情况下如何给用户进行个性化推荐，目的是最优化点击率、转化率或用户 体验（用户停留时间、留存率等）。冷启动问题一般分为用户冷启动、物品冷启动和系统冷启动三大类。

- 用户冷启动是指对一个之前没有行为或行为极少的新用户进行推荐；
- 物品冷启动是指为一个新上市的商品或电影（这时没有与之相关的 评分或用户行为数据）寻找到具有潜在兴趣的用户；
- 系统冷启动是指如何为一个 新开发的网站设计个性化推荐系统。

解决冷启动问题的方法一般是基于内容的推荐。以Hulu的场景为例，对于用 户冷启动来说，我们希望根据用户的注册信息（如：年龄、性别、爱好等）、搜 索关键词或者合法站外得到的其他信息（例如用户使用Facebook账号登录，并得 到授权，可以得到Facebook中的朋友关系和评论内容）来推测用户的兴趣主题。 得到用户的兴趣主题之后，我们就可以找到与该用户兴趣主题相同的其他用户， 通过他们的历史行为来预测用户感兴趣的电影是什么。

同样地，对于物品冷启动问题，我们也可以根据电影的导演、演员、类别、关键词等信息推测该电影所属于的主题，然后基于主题向量找到相似的电影，并将新电影推荐给以往喜欢看这 些相似电影的用户。**可以使用主题模型（pLSA、LDA等）得到用户和电影的主题。**

以用户为例，我们将每个用户看作主题模型中的一篇文档，用户对应的特征 作为文档中的单词，这样每个用户可以表示成一袋子特征的形式。通过主题模型 学习之后，经常共同出现的特征将会对应同一个主题，同时每个用户也会相应地 得到一个主题分布。每个电影的主题分布也可以用类似的方法得到。

**那么如何解决系统冷启动问题呢？**首先可以得到每个用户和电影对应的主题向量，除此之外，还需要知道用户主题和电影主题之间的偏好程度，也就是哪些主题的用户可能喜欢哪些主题的电影。当系统中没有任何数据时，我们需要一些先验知识来指定，并且由于主题的数目通常比较小，随着系统的上线，收集到少量的数据之后我们就可以对主题之间的偏好程度得到一个比较准确的估计。

# 三、LDA和PCA的比较

- **相似：**
  - 从过程来看，PCA和LDA有很大的相似性，最后其实都是求某一个矩阵的特征值，投影矩阵即为特征值对应的特征向量
- **差异：**
  - PCA是非监督降维，LDA是监督降维
  - PCA希望投影后的数据方差尽可能的大（最大可分性），因为其假设方差越大，则所包含的信息越多；而LDA则希望投影后相同类别的组内方差小，而组间方差大。LDA能合理运用标签信息，使得投影后的维度具有判别性，不同类别的数据尽可能的分开。
  - 有标签就尽可能的利用标签的数据（LDA），而对于纯粹的非监督任务，则还是得用PCA进行数据降维。