

TO DO List：

## 1. 模型选型及其训练

- [ ] **1.1 语音识别：**
  - [x] ASR 模型(参考trained_jit_model目录下的模型文件)
    - [x] aishell_1(178h) 
      - [x] conformer
      - [x] transformer   
    - [x] aishell_2(1000h+)
      - [x] conformer
      - [x] transformer
    - [x] 大数据：Aidatatang(140h) + Aishell(178h) + MagicData(712h) + Primewords(99h) + ST-CMDS(110h) + THCHS-30(26h) = 1265h 
      - [ ] conformer
      - [x] transformer
  - [x] models工程化
    - [x] torch JIT .pt --> .zip
  - [ ] ASR 改进：
    - [x] 流式与非流式：选择了非流式
    - [ ] 噪声、鸡尾酒效应
    - [ ] 远场语音识别 vs 近场语音识别
- [ ] **1.2 语音合成：**
  - [ ] TTS 模型训练\讯飞
  - [ ] https://github.com/kan-bayashi/ParallelWaveGAN
    - [ ] [fastspeech2 model](https://github.com/ranchlai/mandarin-tts)
      - [x] 训练测试
      - [ ] 存在问题：无法解决OOV问题
    - [ ] ParallelTTS
      - [ ] 训练中
    - [ ] Tacotron 2
      - [ ] 训练测试
      - [ ] https://github.com/lturing/tacotronv2_wavernn_chinese
- [x] **1.3 对话系统：**
  - [ ] 搭建基于rasa2.2的酒店服务平台
    - [x] v1.0 单轮 (第二期的工作)
    - [x] v1.1 单轮 (现在的工作)
    - [x] v1.2 单轮(语音识别+语音合成+对话系统)
    - [ ] v2.0 多轮 (或结合turing)
    - [ ] v2.1 多轮 + 多语言翻译
    - [ ] v3.0 + 唤醒、自动休眠
    - [ ] v3.1 + 情感
- [ ] **1.4 语音唤醒**
  - [x] 调研
  - [x] 调用讯飞sdk
  - [x] 基于keyword spotting模型训练
  - [ ] 语音唤醒模型部署
- [ ] **1.5 酒店产品对标**
- [ ] 



### 1.1 语音识别

#### 1.1.1 aishell_1(178h)_conformer

- Training 参数：lr 0.002, batch size 16, 3 gpu, acc_grad 4, 240 epochs, dither 0.1
- Decoding 参数：ctc_weight 0.5, average_num 20

| decoding mode          | CER  |
| ---------------------- | ---- |
| attention decoder      | 5.18 |
| ctc greedy search      | 4.94 |
| ctc prefix beam search | 4.94 |
| attention rescoring    | 4.61 |

![aishell_1(178h)_conformer](angbao.assets/aishell_1(178h)_conformer.png)

#### 1.1.2  aishell_1(178h)_transformer

- Training 参数：lr 0.002, batch size 26, 3 gpu, acc_grad 4, 360 epochs, dither 0.1
- Decoding 参数：ctc_weight 0.5, average_num 20

| decoding mode          | CER  |
| ---------------------- | ---- |
| attention decoder      | 5.69 |
| ctc greedy search      | 5.92 |
| ctc prefix beam search | 5.91 |
| attention rescoring    | 5.30 |



#### 1.1.3 aishell_2(1000h+)_transformer

- Training 参数：lr 0.002, batch size 26, 3 gpu, acc_grad 4, 360 epochs, dither 0.1
- Decoding 参数：ctc_weight 0.5, average_num 20

| decoding mode/chunk size | full | 16   | 8    | 4    |
| ------------------------ | ---- | ---- | ---- | ---- |
| attention decoder        | 6.84 | 7.22 | 7.34 | 7.62 |
| ctc greedy search        | 8.01 | 8.91 | 9.28 | 9.73 |
| ctc prefix beam search   | 8.02 | 8.89 | 9.28 | 9.77 |
| attention rescoring      | 6.83 | 7.39 | 7.68 | 7.98 |

![aishell_1(178h)_conformer_cer](angbao.assets/aishell_1(178h)_conformer_cer.png)

#### 1.1.4 aishell_2(1000h+)_conformer



> 实验环境：
>
> - Ubuntu + 2080 12G *3 GPU 
> - python3.6 + pytorch1.8 + torchaudio0.8.0 + tensorboardX

### 1.2 语音合成

### 1.2.1 fastspeech2

- 已经搭建server2，用于传输wav音频文件
- [zerotier](https://my.zerotier.com/login)
- 存在问题：不能解决数字、过长-->应该是OOV的问题

> https://github.com/ranchlai/mandarin-tts

### 1.2.2 ParallelTTS

- nltk包问题：[参考博客](https://blog.csdn.net/weixin_39967072/article/details/111572325)
- [OSError: sndfile library not found](https://blog.csdn.net/xddwz/article/details/109206548)

> https://github.com/atomicoo/ParallelTTS
>
> https://github.com/atomicoo/PTTS-WebAPP

### 1.3 对话系统

#### 1.3.1 搭建基于rasa2.2的酒店服务平台

**第二期工作 v1.0   vs  现在的工作 v1.1**

|        | 第二期工作 v1.0 单轮对话          | 现在的工作 v1.1 单轮对话                                     |
| ------ | --------------------------------- | ------------------------------------------------------------ |
| rasa   | rasa_core+rasa_nlu --> rasa0.4    | rasa 2.2                                                     |
| models | jieba + MITIE预训练中文词向量模型 | [bert](https://mirror.tuna.tsinghua.edu.cn/hugging-face-models/bert-base-chinese-tf_model.h5) |



> 实验环境：
>
> - Ubuntu + 1070 12G*1 GPU
> - python 3.6  + rasa2.2 



> 参考论文及代码：
>
> - [Conformer: Convolution-augmented Transformer for Speech Recognition" (INTERSPEECH 2020)](http://www.interspeech2020.org/index.php?m=content&c=index&a=show&catid=418&id=1331)
> - [transformer：attention is all you need](https://arxiv.org/abs/1706.03762)
> - [espnet code](https://github.com/espnet/espnet)

### 1.4 语音唤醒

**https://blog.csdn.net/liangtianxin002/category_9687627.html**

- [ ] [snowboy: 已经停止维护](https://github.com/Kitt-AI/snowboy)  + [android端](https://github.com/Kitt-AI/snowboy/tree/master/examples/Android)
  - [ ] 但是，https://github.com/seasalt-ai/snowboy
  - [ ] https://github.com/Aculeasis/snowboy-pmdls
  - [ ] https://github.com/xlepotato/Alexa-ChatbotAssistant
- [ ] https://github.com/Picovoice/porcupine
- [ ] [小米](https://paperswithcode.com/paper/attention-based-end-to-end-models-for-small#code)  + [github](https://github.com/Kirili4ik/kws-attention-pytorch)  +  [github](https://github.com/isadrtdinov/kws-attention)  + [wandb](https://www.baidu.com/link?url=m7Ttul1dI0kdu8l34B6yTT55feDluI9jCZJ9FPxoGQk79HwF62yAZzREGIK3TYx_&wd=&eqid=a7b07868001d421c00000006608ffb50)
- [ ] [出门问问kaldi中开源](https://github.com/kaldi-asr/kaldi/tree/master/egs/mobvoi/v1)  + [数据集](https://www.openslr.org/87)  + [paper](https://paperswithcode.com/search?q_meta=&q_type=&q=Wake+Word+Detection)
- [ ] [kaldi中的唤醒](https://github.com/kaldi-asr/kaldi/blob/master/src/online2/online-nnet3-wake-word-faster-decoder.cc)
- [ ] [aishell](https://github.com/kaldi-asr/kaldi/tree/master/egs/hi_mia/v1)  + [数据集](https://www.openslr.org/85)  + [paper](https://arxiv.org/pdf/2005.08347.pdf)  + [报告](https://mp.weixin.qq.com/s/bswlrv_ixG-lsAHUKaCfSA)  + [data 介绍](https://blog.csdn.net/liangtianxin002/article/details/104174438)
- [ ] 换种思路-->无唤醒:[博客](https://www.zhihu.com/question/413693975/answer/1856180381) + [讯飞](https://aiui.xfyun.cn/solution/wakeup) +[blog](https://blog.csdn.net/q4878802/article/details/47778629)
- [ ] [pocketsphinx](https://blog.51cto.com/feature09/2300352)
- [ ] KWS比赛:https://github.com/janson9192/autokws2021
- [ ] 自己录制语音唤醒：https://github.com/LearnedVector/A-Hackers-AI-Voice-Assistant

**https://www.automl.ai/**

**https://competitions.codalab.org/competitions/28890#learn_the_details**

**https://competitions.codalab.org/competitions/30686#results**

https://paperswithcode.com/paper/auto-kws-2021-challenge-task-datasets-and#code

https://paperswithcode.com/search?q_meta=&q_type=&q=KWS

https://github.com/JetRunner/dogwhistle

## 2. 部署工作

- [ ] 跳板
  - [ ] 13824771243@163.com  ([zerotier](https://my.zerotier.com/))  ([参考](https://zhuanlan.zhihu.com/p/83849371))
- [x] **2.1 腾讯云端部署**
  - [x] 语音识别云端
  - [x] 语音合成云端（性能未优化）
  - [x] rasa服务器  **https://github.com/XudongLiu/rasa2_chatbot_medical**
- [x] **2.2 安卓系统部署**
  - [x] 对话系统客户端部署
  - [x] 语音识别编译+部署（基于transformer模型）
  - [x] 语音合成部署 
  - [ ] 综合部署
- [ ] 2.3 工程项目部署理论
  - [ ] [rasa api](https://blog.csdn.net/lly1122334/article/details/106072969)
  - [ ] [wukong项目](https://wukong.hahack.com/)  [github](https://github.com/wzpan/wukong-robot)

> 参考：
>
> - https://github.com/pytorch/android-demo-app
> - https://github.com/Dustyposa/rasa_ch_faq/



### 2.1 腾讯云端部署

- 服务器配置：CPU 1core + memory 2GB 
- 服务器 ssh -p 22 root@1.15.185.176  （密码:LZT13531885442@lzt）

#### 2.1.1 语音识别部署

- 实验室服务器，docker部署(通道问题)

- 腾讯云服务器，需要安装cmake+更新[g++]()、ldd版本问题、GLIBCXX_3.4.21 not found https://itbilu.com/linux/management/NymXRUieg.html

  - SoundRecognizer.js:86 Uncaught TypeError: Cannot read property 'getUserMedia' of undefined：

- 已经完成服务器端搭建，语音识别服务器步骤：

  - ```
    cd audio
    ```

  - 开启服务端：

    ```
    export GLOG_logtostderr=1
    export GLOG_v=2
    model_dir=/root/audio/model/20210327_unified_transformer_exp_server
    ./build/websocket_server_main \
    --port 9998 \
    --chunk_size 16 \
    --model_path $model_dir/final.zip \
    --dict_path $model_dir/words.txt 2>&1 | tee server.log
    ```

  - 直接调用接口：

    ```
    export GLOG_logtostderr=1
    export GLOG_v=2
    wav_path=/home/tower/project/paper/wenet_server/runtime/server/x86/wav/test_A.wav
    ./build/websocket_client_main \
     --host 1.15.185.176 --port 9998 \
     --wav_path $wav_path 2>&1 | tee client.log
    ```

  - 打开client：

    ```
    python app.py
    ```

#### 2.1.2 语音合成部署

- 基于android，使用flask搭建服务器
- 出现OOV问题 <--  fastTTS
- [nltk问题](https://blog.csdn.net/weixin_39967072/article/details/111572325)

#### 2.1.3 rasa服务器

- ```
  cd rasa_home/rasa_server_v2.0/
  ```

- 开启服务端：

  ```
  rasa run actions
  
  rasa run -m models --enable-api --endpoints.yml
  ```

- 客户端可用安卓/web



> - 安装了docker compose版本：passd：Tower123
> - https://github.com/Dustyposa/rasa_ch_faq
> - https://github.com/whitespur/rasa_shopping_bot/tree/master/restaurantbot

#### 2.1.4 snowboy

- 外部存储访问过期问题:https://www.cnblogs.com/wytings/p/5226101.html



### 2.2 安卓系统部署

#### 2.2.1 对话系统客户端部署





> - https://github.com/machaao/rasa-sample-nlu-bot
> - https://github.com/houcembenmahfoudh/STT_android_TTS
> - https://github.com/Horizon733/Covid-Chatbot-app
> - https://github.com/machaao/rasa-sample-nlu-bot
> - https://github.com/vukihai/Rasa-android-client
> - https://github.com/Ahlam-dev/RasaBotwithAndroidApp
> - [MiraiAndroid,开源项目](https://github.com/mzdluo123/MiraiAndroid)
> - [rasa_android语音](https://github.com/just-ai/aimybox-android-assistant)
>

#### 2.2.2 语音识别编译+部署

- [torch jit](https://pytorch.org/docs/stable/_modules/torch/jit.html) :JIT（Just-In-Time）是一组编译工具，用于弥合 PyTorch 研究与生产之间的差距。torch script 可以被序列化的用于C++中。

> 环境：
>
> - windows10 + android studio + android10



2.21.4.21

- 做一个完整的demo
- 语音识别差，但是可不可以提取关键词，然后进行意图识别
-  不用TTS，用wav文件
- 特定领域酒店的数据集



> 参考：
>
> [rasa官网](https://rasa.com/docs/rasa)
>
> [rasaX官网](https://rasa.com/docs/rasa-x/installation-and-setup/install/docker-compose)
>
> [tegnxunAI](https://ai.tencent.com/ailab/en/index/)

## 3. 前端工作

- [树莓派4mic](https://wiki.seeedstudio.com/cn/ReSpeaker_4_Mic_Array_for_Raspberry_Pi/)
- https://wiki.seeedstudio.com/cn/ReSpeaker_4_Mic_Array_for_Raspberry_Pi/



https://www.corvin.cn/2240.html

参考:https://blog.csdn.net/Barry_J/article/details/80586242





- 项目代码：https://github.com/alphacep/vosk-api
- https://github.com/alphacep/vosk-server

> vosk：https://alphacephei.com/vosk/
>
> 安卓集成可以参考vosk官网的文档[demo](

- 项目代码：https://github.com/ranchlai/mandarin-tts
  - 按照github进行配置即可
- paper：https://arxiv.org/pdf/2006.04558.pdf

> 主要用于生成“音频文件”，便于后续工程